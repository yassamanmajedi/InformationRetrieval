{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MIR_phase1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5O3xz7oPosg"
      },
      "source": [
        "<div style=\"direction:rtl;line-height:300%;font-family:BNazanin,\">\n",
        "<font face=\"XB Zar\" size=5>\n",
        "<div align=center>\n",
        "<font face=\"B Titr\" size=5>\n",
        "<p></p><p></p>\n",
        "بسمه تعالی\n",
        "<p></p>\n",
        "</font>\n",
        "<p></p>\n",
        "<font>\n",
        "<br>\n",
        "درس بازیابی پیشرفته اطلاعات\n",
        "<br>\n",
        "مدرس: دکتر فاطمه لشکری\n",
        "</font>\n",
        "<p></p>\n",
        "<br>\n",
        "<font>\n",
        "<b>فاز اول پروژه</b>\n",
        "</font>\n",
        "<br>\n",
        "<br>\n",
        "موعد تحویل: ۸ آبان ۱۴۰۰\n",
        "<br>\n",
        "<font size=4.8>\n",
        "دستیاران آموزشی مربوط به این فاز: سینا کاظمی - پارسا اسکندر\n",
        "</font>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<font>\n",
        "دانشگاه صنعتی شریف\n",
        "<br>\n",
        "دانشکده مهندسی کامپیوتر\n",
        "<br>\n",
        "<br>\n",
        "</font>\n",
        "</div>\n",
        "</font>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i47HeS9NRU7B"
      },
      "source": [
        "<div dir=\"rtl\">\n",
        "<h2>\n",
        "مقدمه\n",
        "</h2>\n",
        "<p>\n",
        "هدف فاز اول پروژه پیاده سازی یک سیستم بازیابی اطلاعات است.\n",
        "این فاز پروژه از ۴ مرحله تشکیل شده است.\n",
        "بخش اول به پیش پردازش متنی داده ها می پردازد که شامل نرمال سازی متن (Normalization) ، جداسازی لغات (Tokenization) ، حذف لغات پرتکرار و ... می باشد. بخش دوم مربوط به نمایه سازی (indexing) خواهد بود. در بخش سوم باید روی این نمایه فشرده سازی صورت بگیرد. در بخش چهارم باید پرسمان ورودی کاربر را تصحیح کنید.\n",
        "</p>\n",
        "<p>\n",
        "۲ سری مجموعه دادگان در اختیار شما قرار گرفته است که یکی مربوط به زبان فارسی ( persian_dataset.csv ) و دیگری مربوط به زبان انگلیسی ( english_dataset.csv ) می باشد.\n",
        "مجموعه فارسی بخشی از مستندات ویکی پدیای فارسی می باشد و مجموعه انگلیسی مربوط به اخبار است.\n",
        "</p>\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fi2P02O_RviE"
      },
      "source": [
        "<div dir=\"rtl\">\n",
        "<h2>\n",
        "بخش اول ( پیش پردازش اولیه متن )\n",
        "</h2>\n",
        "<p>\n",
        "در این بخش از پروژه باید ابتدا مجموعه فایل هایی که در اختیارتان قرار گرفته است را بخوانید، برای خواندن و کار کردن با فایل‌ها پیشنهاد می‌شود از کتابخانه‌ی \n",
        "<a href=\"https://pandas.pydata.org/\">\n",
        "pandas\n",
        "</a> \n",
        "استفاده کنید.\n",
        "این کتابخانه توابعی برای \n",
        "<a href=\"https://www.geeksforgeeks.org/python-read-csv-using-pandas-read_csv/\">\n",
        "خواندن\n",
        "</a> \n",
        "و \n",
        "<a href=\"https://towardsdatascience.com/pandas-dataframe-basics-3c16eb35c4f3\">\n",
        "کار کردن\n",
        "</a> \n",
        "راحت‌تر با دیتاها در اختیار شما قرار می‌دهد .\n",
        "\n",
        "\n",
        " سپس به ترتیب مراحل پیش پردازش متنی که در ادامه آمده است را روی آنها اعمال کنید. برای کار های پیش رو می توانید از کتابخانه های \n",
        "<a href=\"https://www.nltk.org/\">\n",
        "NLTK\n",
        "</a>\n",
        " برای زبان انگلیسی و هضم ( \n",
        "   <a href=\"http://www.sobhe.ir/hazm/\">\n",
        "hazm\n",
        "</a> \n",
        " ) برای زبان فارسی استفاده کنید\n",
        "</p>\n",
        "<ul>\n",
        "<li>\n",
        "نرمال سازی متنی (normalization): برای یکسان سازی متون می توانید از توابع معرفی شده استفاده کنید. اما در صورتی که میخواهید خودتان پیاده سازی کنید باید پیاده \n",
        "سازیتان شامل برگرداندن لغات به ریشه (stemming)\n",
        "، case folding ( برای یکسان سازی متون انگلیسی ) و بقیه موارد مطرح شده در درس باشد.\n",
        "</li>\n",
        "<li>\n",
        "جداسازی (tokenization): برای اینکار میتوانید از کتابخانه های معرفی شده در بالا استفاده نمایید\n",
        "</li>\n",
        "<li>\n",
        "حذف علائم نگارشی: هر متنی در هر زبانی یه سری علائم نگارشی دارد که می بایست حذف شوند مانند: ویرگول ، دونقطه و ...\n",
        "</li>\n",
        "<li>\n",
        "یافتن و حذف لغات پرتکرار (stopwords): در این بخش، حذف درصد معقولی از لغات پرتکرار مورد نظر است. برای این منظور لازم است تا همه متن را پردازش کنید و نسبت به حجم متن، کلماتی که پرتکرار هستند را نمایش دهید. این نسبت را طوری در نظر بگیرید که کلمات پرتکرار به دست آمده تا حد خوبی منطقی و کافی باشند.\n",
        "</li>\n",
        "<li>\n",
        "برگرداندن کلمات به ریشه (stemming, lemmatizing): در نهایت کلمات را به حالت ساده و پایه آنها تبدیل کنید.\n",
        "</li>\n",
        "</ul>\n",
        "<p>\n",
        "برای پیاده سازی این بخش تابع پیاده سازی prepare_text را پر کنید.\n",
        "برای نمایش لغات پرتکرار می توانید از هیستوگرام و یا لیست ساده ای از کلمات استفاده کنید.\n",
        "</p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3gsB7gzYIlo"
      },
      "source": [
        "def prepare_text(raw_text):\n",
        "    \"\"\"Preprocesses the text with tokenization, case folding, stemming and lemmatization\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    raw_text : str\n",
        "        The title or plot of a movie\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    list\n",
        "        A list of tokens\n",
        "    \"\"\"\n",
        "\n",
        "    # TODO: tokenize, case_folding, stem, lemmatize\n",
        "    return [\"edvard\", \"am\", \"a\", \"run\", \"he\", \"am\", \"always\", \"run\"]\n",
        "\n",
        "prepare_text(\"Edvard was a Runner. He was always running.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0joZDmDIYLh8"
      },
      "source": [
        "def get_stop_words():\n",
        "    \"\"\"Detects stop-words\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    dict\n",
        "        A dictionary of terms with their repetition\n",
        "    \"\"\"\n",
        "\n",
        "    # TODO: find top most repetitive terms and report them\n",
        "    return {\"a\":1000, \"the\":800, \"am\":500}\n",
        "\n",
        "get_stop_words()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzpC6pjdSQ6U"
      },
      "source": [
        "<div dir=\"rtl\">\n",
        "<h2>\n",
        "بخش دوم ( نمایه سازی )\n",
        "</h2>\n",
        "<p>\n",
        "در این بخش پیاده سازی نمایه جایگاهی (Positional) و نمایه Bigram مطلوب است. برای نمایه جایگاهی باید به ازای هر لغت، لیستی از اسناد شامل آن لغت و جایگاه (ها) هر لغت در آن سند داشته باشید و برای نمایه Bigram نیز ترکیب های دوحرفی تمامی کلمات موجود در لغت نامه که این ترکیب در آنها موجود است را ذخیره کنید. این نمایه برای اصلاح پرسمان مورد استفاده قرار خواهد گرفت. نمایه شما باید پویا باشد یعنی با حذف سند از نمایه نیز حذف شود و با اضافه کردن سند یا اسناد در طول اجرای برنامه به نمایه اضافه شود. همچنین بعد از نمایه سازی باید قادر باشید نمایه را در فایلی ذخیره کرده و از آن بخوانید. پویا بودن نمایه و ذخیره سازی آن را برای هردو نوع نمایه در نظر بگیرید.\n",
        "</p>\n",
        "<p>\n",
        "نکات پیاده سازی:\n",
        "</br>\n",
        "برای سادگی پیاده سازی برای هر کارکرد خواسته شده در توضیحات بالا یک تابع پیاده سازی کنید. برای مثال دوتابع برای حذف و اضافه سند به نمایه و توابعی برای ذخیره سازی و بارگزاری نمایه ها و ... در نظر بگیرید.\n",
        "</p>\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJBDwr7ZSQw8"
      },
      "source": [
        "<div dir=\"rtl\">\n",
        "<h2>\n",
        "بخش سوم ( فشرده سازی نمایه ها)\n",
        "</h2>\n",
        "در این بخش هدف، فشرده‌سازی نمایه‌های ساخته‌شده به دو روش \n",
        "variable code \n",
        "و\n",
        "gamma code \n",
        "است.\n",
        "\n",
        "<h3>\n",
        "نکات پیاده‌سازی \n",
        "</h3>\n",
        " هر دو روش پیاده‌سازی شود ولی برای ذخیره‌سازی نمایه‌ها در فایل و استفاده‌ از آن در بخش‌های بعد یکی از دو روش به دلخواه استفاده شود.\n",
        " <br>\n",
        "برای ذخیره نمایه در فایل می‌توانید از JSON \n",
        "یا\n",
        "pickle \n",
        "استفاده کنید.\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqOITrpcU8ef",
        "outputId": "4a11351f-d214-495e-eb3f-7dc56863cd58"
      },
      "source": [
        "def store_index(path, compression_type):\n",
        "    \"\"\"Stores the index in a file\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    path : str\n",
        "        Path to store the file\n",
        "\n",
        "    compression_type : str\n",
        "        Could be one of the followings:\n",
        "        - no-compression\n",
        "        - gamma-code\n",
        "        - variable-byte\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    int\n",
        "        The size of the stored file\n",
        "    \"\"\"\n",
        "\n",
        "    # TODO: compress and store positional_index\n",
        "    size_of_file = 1024\n",
        "    return size_of_file\n",
        "\n",
        "store_index(\"path/to/file.json\", \"no-compression\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1024"
            ]
          },
          "execution_count": 55,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYN9I4_BD178",
        "outputId": "4a11351f-d214-495e-eb3f-7dc56863cd58"
      },
      "source": [
        "def load_index(path, compression_type):\n",
        "    \"\"\"Loads the index from a file\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    path : str\n",
        "        Path of the file to load from\n",
        "\n",
        "    compression_type : str\n",
        "        Could be one of the followings:\n",
        "        - no-compression\n",
        "        - gamma-code\n",
        "        - variable-byte\n",
        "    \"\"\"\n",
        "\n",
        "    # TODO: load and decompress positional_index\n",
        "    return\n",
        "\n",
        "load_index(\"path/to/file.json\", \"no-compression\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1024"
            ]
          },
          "execution_count": 55,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mdCFLLySQab"
      },
      "source": [
        "<div dir=\"rtl\">\n",
        "<h2>\n",
        "بخش چهارم ( اصلاح پرسمان )\n",
        "</h2>\n",
        "در صورتی که پرسمان ورودی دارای غلط املایی باشد ( لغت‌ غلط لغتی است که در لغت‌نامه موجود نیست ) لازم است که با جست‌وجوی لغت‌های احتمالی و انتخاب بهترین لغت به ادامه‌ی جست‌وجو با پرسمان اصلاح‌شده پرداخته‌شود.\n",
        "برای این‌کار لازم است ابتدا به وسیله‌ی روش bigram \n",
        "و معیار jaccard \n",
        "نزدیک‌ترین لغات به لغت با غلط املایی را پیدا کنید و سپس بهترین لغت میان آن‌ها را با استفاده از معیار \n",
        "edit distance \n",
        "بیابید.\n",
        "<h3>\n",
        "نکات پیاده‌سازی:\n",
        "</h3>\n",
        "یک تابع پیاده‌سازی شود که ورودی خام را گرفته و متن تصحیح شده‌ی آن‌را نمایش دهد. دقت کنید ورودی و خروجی هر دو رشته‌ی متنی هستند.\n",
        "</br>\n",
        "نیازی به ذخیره‌سازی و فشرده‌سازی نمایه بایگرم نیست. همچنین می‌توانید از کد آماده برای محاسبه edit distance استفاده کنید.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMZTstsbL1G3"
      },
      "source": [
        "def create_bigram_index():\n",
        "    \"\"\"Creates the bigram index for spell correction\"\"\"\n",
        "\n",
        "    # TODO: create bigram index\n",
        "    bigram = {\"he\": [\"hello\", \"hell\", \"he\", \"her\"], \"el\": [\"telephone\", \"else\"]}\n",
        "    return bigram\n",
        "\n",
        "create_bigram_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "sL3E8C-nL1yG",
        "outputId": "d4da236e-728c-4419-e80e-e8a36bd4e85d"
      },
      "source": [
        "def get_corrected_text(raw_text):\n",
        "    \"\"\"Corrects the query\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    raw_text : str\n",
        "        Input text that could be a title or a plot\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    str\n",
        "        The corrected text\n",
        "    \"\"\"\n",
        "\n",
        "    # TODO: correct the query using bigram, jaccard, and edit-distance\n",
        "    corrected_text = \"the adventure of sherlock holmes\"\n",
        "    return corrected_text\n",
        "\n",
        "get_corrected_text(\"the adevntures of herlock holmes\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'the adventure of sherlock holmes'"
            ]
          },
          "execution_count": 58,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epLKVSVaSPxN"
      },
      "source": [
        "<div dir=\"rtl\">\n",
        "<h2>\n",
        "بخش پنجم ( نکات و جمع بندی پایانی )\n",
        "</h2>\n",
        "<ol>\n",
        "<li>\n",
        "گزارشی از پیاده سازی هر بخش تهیه در پایان هر بخش در همین فایل ژوپیتر قرار دهید.\n",
        "</li>\n",
        "<li>\n",
        "تنها زبان برنامه نویسی مجاز پایتون می باشد\n",
        "</li>\n",
        "<li>\n",
        "کد ها و توابع از نظر شباهت بررسی خواهد شد و با موارد مشابه و تقلب طبق آیین نامه تمارین درسی برخورد خواهد شد.\n",
        "</li>\n",
        "<li>\n",
        "فایل نوت بوک را زیپ کنید و با فرمت StudentNumber_phase1 ارسال نمایید.\n",
        "</li>\n",
        "<li>\n",
        "سیستم را بهینه پیاده سازی کنید تا در زمان کمتری بارگزاری و نمایه سازی شود.\n",
        "</li>\n",
        "<li>\n",
        "به ۵ پیاده سازی برتر نمره امتیازی تعلق میگیرد.\n",
        "</li>\n",
        "</ol>\n",
        "<p>\n",
        "\n",
        "در انجام پروژه اگر سوالی داشتید می توانید با ایمیل\n",
        " sinakazemi1998@gmail.com \n",
        " و\n",
        " parsa.eskandar@gmail.com\n",
        " در ارتباط باشید.\n",
        "</p>\n",
        "</div>"
      ]
    }
  ]
}