{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88a39194",
   "metadata": {
    "id": "88a39194"
   },
   "source": [
    "<center>\n",
    "\n",
    "# فاز دوم پروژه\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2219990",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "     در صورت هرگونه سوال به ایمیل‌های زیر پیام داده یا از طریق سایر پلتفرم‌ها(در تلگرام از\n",
    "    alirezadaqiq یا sina_tav ) پیگیری کنید\n",
    "    \n",
    "[Sina Tavakkoli](mailto:stavakkoli1999@gmail.com)\n",
    "     <br>\n",
    "[Alireza Daqiq](mailto:alireza.daghigh1999@gmail.com)\n",
    "    \n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4464e5a9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "657af262",
   "metadata": {
    "id": "657af262"
   },
   "source": [
    "<div dir=\"rtl\">\n",
    "\n",
    "## I. خلاصه انجام پروژه\n",
    "\n",
    "در این تمرین, می‌خواهیم یک تصحیح‌کننده‌ی غلط‌املایی احتمالاتی بسازیم که غلط‌های موجود در کوئری را اصلاح کند.\n",
    "   ورودی ما در این مسئله, کوئری $R$ است و هدف پیدا کردن کوئری درست $Q$ است که احتمال $P(Q\\mid R)$ را بیشینه کند. \n",
    "    بر اساس قضیه‌ی بیز داریم :\n",
    "$$\n",
    "    P(Q\\mid R) = \\frac{P(R\\mid Q)P(Q)}{P(R)}\\propto P(R\\mid Q)P(Q).\n",
    "$$\n",
    "از آنجایی که هدف ما پیدا کردن $Q$یی است که عبارت $P(Q\\mid R)$ را بیشینه کند, تنها کافی‌ست که $P(R\\mid Q)P(Q)$ را بیشینه کنیم.\n",
    "    حال با توجه به چیزهایی که گفته شد, مصحح غلط‌املایی احتمالاتی ما باید چهار بخش داشته باشد:\n",
    "  1.  **مدل ‌زبانی.**(Language Model) \\\n",
    "      توزیع اولیه‌ی یونیگرام‌ها و بایگرام‌ها را حساب می‌کند. این کار به ما اجازه می‌دهد که $P(Q)$ حساب کنیم. ما از maximum-likelihood estimation استفاده می‌کنیم, که وقوع توکن یونیگرام و بایگرام‌ها را در training corpus برای تعیین کردن احتمالات اولیه می‌شمرد.\n",
    "  2. **مدل احتمال ویرایش.** (Edit Probability Model)\\\n",
    "      احتمال خطاهایی که ممکن است در یک کوئری اتفاق بیافتد را حساب می‌کند. این به ما اجازه می‌دهد که $P(R\\mid Q)$ را محاسبه کنیم. به طور خاص، این کامپوننت احتمال کرکترهایی را حساب می‌کند که در یک کوئری ترم به اشتباه حذف، درج، جایگزین یا ترنسپوز شده‌اند.\n",
    "  3. **تولیدکننده‌ی نامزدها.** (Candidate Generator)\\\n",
    "      کوئری خام $R$ که توسط کاربر ثبت شده است را می‌گیرد و نامزد‌های $Q$ را تولید می‌کند.\n",
    "  4. **امتیازدهنده‌ی نامزدها.** (Candidate Scorer)\\\n",
    "      موارد (1), (2) و (3) را برای محاسبه‌ی $Q^{*} = \\arg\\max_{Q}P(Q\\mid R)$ ترکیب می‌کند. یعنی برای هر $Q$ که توسط تولید‌کننده‌ی نامزدها تولید شده است، امتیازدهنده از مدل‌زبان برای محاسبه‌ی $P(Q)$ و از مدل احتمال ویرایش برای محاسبه‌ی $P(R\\mid Q)$ استفاده می‌کند و در نهایت $Q$ را انتخاب می‌کند که مقدار $P(Q)P(R\\mid Q)$ بیشینه می‌کند.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Z3TkKKFXQSx6",
   "metadata": {
    "id": "Z3TkKKFXQSx6"
   },
   "source": [
    "<div dir=\"rtl\">\n",
    "\n",
    "## II. جزئیات پروژه\n",
    "\n",
    "\n",
    "  1. [تسک اول: تصحیح املا با استفاده از Uniform Edit Costs](#uniform)\n",
    "  2. [تسک دوم: تصحیح املا با استفاده از Empirical Edit Costs](#empirical)\n",
    "  3. [گزارش مکتوب](#written)\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb003c31",
   "metadata": {
    "id": "fb003c31"
   },
   "source": [
    "<a id=\"dataset\"></a>\n",
    "\n",
    "<div dir=\"rtl\">\n",
    "\n",
    "## III. دیتاست\n",
    "\n",
    "\n",
    "برای این تمرین, ما برای داده‌های تمرین و تست  از یکی از دیتا‌ست‌های دانشگاه استنفورد با اندکی تغییرات استفاده کردیم\n",
    "برای متون هم ازیکی از آزمایشگاه‌های این دانشگاه بهره بردیم.\n",
    "\n",
    "   <div dir=\"rtl\">\n",
    "   دیتاست از این <a href=\"https://drive.google.com/file/d/17ukKiVAYtbBuL_zI8_2IhZ8uzxkMJdPs/view?usp=sharing\"> لینک </a> قابل دسترسی است. آن‌را دانلود کرده و کنار notebook قرار دهید و سلول زیر را اجرا کنید . دیتاست شامل سه بخش زیر است:\n",
    "    </div>\n",
    "    <ul>\n",
    "       <li>  corpusها : در پوشه مربوط به آن ۱۰ فایل می‌بینید که هر خط هر فایل از یک مستند است. از tokenهای این بخش در ساخت model استفاده کنید</li>\n",
    "       <li> training set: شامل جفت‌هایی از عبارات غلط و درست‌ آنها که با حداکثر یک عدد که edit distanceآنهاست جدا شده‌اند</li>\n",
    "       <li>  dev set : در پوشه مربوطه سه فایل وجود دارد, ورژن عبارات با غلط املایی, ورژن صحیح آنها در gold.txt  و ورژن تصحیح شده توسط google در google.txt </li>\n",
    "    </ul>    \n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02cc2ac",
   "metadata": {
    "id": "e02cc2ac"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e64022bd",
   "metadata": {
    "id": "e64022bd",
    "outputId": "aa1b2799-ea60-4cf0-9340-e34a932e34f4"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Import modules\n",
    "import math\n",
    "import os\n",
    "import urllib.request\n",
    "import zipfile\n",
    "from collections import Counter\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8056cf7a",
   "metadata": {
    "id": "8056cf7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data unzipped to MIR2-data...\n",
      "\n",
      "Directory Structure:\n",
      "MIR2-data/\n",
      "  - dev_set/\n",
      "  - training_set/\n",
      "  - corpus/\n"
     ]
    }
   ],
   "source": [
    "# Download dataset\n",
    "# go to this url and download dataset https://drive.google.com/file/d/17ukKiVAYtbBuL_zI8_2IhZ8uzxkMJdPs/view?usp=sharing\n",
    "data_dir = 'MIR2-data'\n",
    "\n",
    "# Unzip dataset\n",
    "with zipfile.ZipFile('{}.zip'.format(data_dir), 'r') as zip_fh:\n",
    "    zip_fh.extractall()\n",
    "print('Data unzipped to {}...\\n'.format(data_dir))\n",
    "\n",
    "# Print the directory structure\n",
    "print('Directory Structure:')\n",
    "print(data_dir + os.path.sep)\n",
    "for sub_dir in os.listdir(data_dir):\n",
    "    if not sub_dir.startswith('.'):\n",
    "        print('  - ' + sub_dir + os.path.sep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2130863a",
   "metadata": {},
   "source": [
    "<div dir='rtl'>\n",
    "در تغییر ساختار کد در هر بخش آزاد هستید, فقط خروجی‌ها باید مورد انتظار بوده و تغییر داده شده در گزارش مکتوب آورده شود\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764617ad",
   "metadata": {
    "id": "764617ad"
   },
   "source": [
    "<div dir=\"rtl\">\n",
    "\n",
    "<a id='uniform'></a>\n",
    "## IV. تسک اول:\n",
    "\n",
    "### IV.1. مدل‌زبان\n",
    "\n",
    "  حال می‌خواهیم یک مدل‌زبان برا پیشبینی $P(Q)$ از training corpusها بسازیم. رفتار ما با $P(Q)$ به صورت مجموعه‌ای از ترم‌های $(w_1, \\ldots, w_n)$ است که:\n",
    "  $$\n",
    "P(w_1, \\ldots, w_n) = P(w_1)P(w_2\\mid w_1)\\cdots P(w_n\\mid w_{n-1}),\n",
    "$$\n",
    "  که $P(w_1)$ در واقع احتمال یونیگرام ترم$w_1$  و $P(w_{i}\\mid w_{i-1})$ و احتمال بایگرام $(w_{i-1}, w_i)$ برای $i \\in \\{2, \\ldots, n\\}$ است.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc7e86e",
   "metadata": {
    "id": "6cc7e86e"
   },
   "source": [
    "<div  style=\"direction:rtl\" >\n",
    "\n",
    "مدل‌زبان برای به دست آوردن احتمالات از MLE استفاده می کند:\n",
    "$$\n",
    "\\begin{align*}\n",
    "  P_{\\text{MLE}}(w_i) & = \\frac{\\texttt{count}(w_i)}{T},\n",
    "  &\n",
    "  P_{\\text{MLE}}(w_i\\mid w_{i-1}) & = \\frac{\\texttt{count}((w_{i}, w_{i-1}))}{\\texttt{count}(w_{i-1})},\n",
    "\\end{align*}\n",
    "$$\n",
    "که $T$ تعداد کل توکن‌ها در corpus است و $\\texttt{count}$ تعداد یونیگرام‌ها و بایگرام‌هاست.\n",
    "\n",
    "برای به‌دست آوردن count برای یونیگرام‌ها و بایگرام‌ها در corpus، کد زیر را کامل کنید:\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e19b1385",
   "metadata": {
    "id": "e19b1385"
   },
   "outputs": [],
   "source": [
    "\n",
    "class LanguageModel:\n",
    "    \"\"\"Models prior probability of unigrams and bigrams.\"\"\"\n",
    "\n",
    "    def __init__(self, corpus_dir='MIR2-data/corpus', lambda_=0.1):\n",
    "        \"\"\"Iterates over all whitespace-separated tokens in each file in\n",
    "        `corpus_dir`, and counts the number of occurrences of each unigram and\n",
    "        bigram. Also keeps track of the total number of tokens in the corpus.\n",
    "\n",
    "        Args:\n",
    "            corpus_dir (str): Path to directory containing corpus.\n",
    "            lambda_ (float): Interpolation factor for smoothing by unigram-bigram\n",
    "                interpolation. You only need to save `lambda_` as an attribute for now, and\n",
    "                it will be used later in `LanguageModel.get_bigram_logp`. See Section\n",
    "                IV.1.2. below for further explanation.\n",
    "        \"\"\"\n",
    "        self.lambda_ = lambda_\n",
    "        self.total_num_tokens = 0        # Counts total number of tokens in the corpus\n",
    "        self.unigram_counts = Counter()  # Maps strings w_1 -> count(w_1)\n",
    "        self.bigram_counts = Counter()   # Maps tuples (w_1, w_2) -> count((w_1, w_2))\n",
    "\n",
    "        ### Begin your code\n",
    "\n",
    "        ### End your code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd00ef9",
   "metadata": {
    "id": "9dd00ef9"
   },
   "source": [
    "<div dir=\"rtl\">\n",
    "\n",
    "   حال که تعداد یونیگرام‌ها و بایگرام‌ها را محاسبه کردیم، باید احتمال کوئری‌ها را نیز بسنجیم. قبل از ان به بایگرام‌هایی بپردازیم که هیچ‌گاه در corpus ندیدیم.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bbe094",
   "metadata": {
    "id": "a4bbe094"
   },
   "source": [
    "<div dir=\"rtl\">\n",
    "\n",
    "#### IV.1.2.  هموارسازی با استفاده از درون‌یابی ( Smoothing by Interpolation)\n",
    "\n",
    "مدل احتمال یونیگرام به عنوان مجموعه لغات ما هم خواهد بود. چون فرض می‌کنیم که کوئری ما از مستند corpus آمده است، درنتیجه در احتمالات یونیگرام خود نیازی به [هموارسازی لاپلاس](https://en.wikipedia.org/wiki/Additive_smoothing) نداریم، چون نامزدهای ما از همین لغت‌نامه آمده‌اند. اما حتی اگر دو کوئری ترم داشتیم که هردوی آن‌ها جزو کوئری زبان ما بودند، تضمینی نیست که بایگرام متناظر آن‌ها در training corpus وجود داشته باشند. برای مدیریت این پراکندگی داده ما احتمالات یونیگرام و بایگرام را برای به دست آوردن احتمال شرطی نهایی خود *درون‌یابی* می‌کنیم:\n",
    "$$\n",
    "P(w_2\\mid w_1) = \\lambda P_{\\text{MLE}}(w_2) + (1 - \\lambda)P_{\\text{MLE}}(w_2\\mid w_1).\n",
    "$$\n",
    "با قرار دادن یک مقدار کوچک به جای $\\lambda$ (برای مثال، 0.1) شروع می‌کنیم و سپس با تغییر این متغیر آزمون و خطا می‌کنیم تا دقت تصحیح ما در دیتاست توسعه بالاتر برود. توجه کنید که در این مورد برای دیتاست مورد نظر overﬁt نکنید. می‌توانید یک قسمت کوچک از داده‌های خود را برای tune کردن پارامترها نگه‌دارید.\n",
    "\n",
    "توابع زیر را برای کامل کردن کلاس `LanguageModel` بنویسید."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b92a780e",
   "metadata": {
    "id": "b92a780e"
   },
   "outputs": [],
   "source": [
    "# NOTE: Syntax on the following line just extends the `LanguageModel` class\n",
    "class LanguageModel(LanguageModel):\n",
    "    def get_unigram_logp(self, unigram):\n",
    "        \"\"\"Computes the log-probability of `unigram` under this `LanguageModel`.\n",
    "\n",
    "        Args:\n",
    "            unigram (str): Unigram for which to compute the log-probability.\n",
    "\n",
    "        Returns:\n",
    "            log_p (float): Log-probability of `unigram` under this\n",
    "                `LanguageModel`.\n",
    "        \"\"\"\n",
    "        ### Begin your code\n",
    "\n",
    "        ### End your code\n",
    "\n",
    "    def get_bigram_logp(self, w_1, w_2):\n",
    "        \"\"\"Computes the log-probability of `unigram` under this `LanguageModel`.\n",
    "\n",
    "        Note:\n",
    "            Use self.lambda_ for the unigram-bigram interpolation factor.\n",
    "\n",
    "        Args:\n",
    "            w_1 (str): First word in bigram.\n",
    "            w_2 (str): Second word in bigram.\n",
    "\n",
    "        Returns:\n",
    "            log_p (float): Log-probability of `bigram` under this\n",
    "                `LanguageModel`.\n",
    "        \"\"\"\n",
    "        ### Begin your code\n",
    "\n",
    "        ### End your code\n",
    "\n",
    "    def get_query_logp(self, query):\n",
    "        \"\"\"Computes the log-probability of `query` under this `LanguageModel`.\n",
    "\n",
    "        Args:\n",
    "            query (str): Whitespace-delimited sequence of terms in the query.\n",
    "\n",
    "        Returns:\n",
    "            log_p (float): Log-probability assigned to the query under this\n",
    "                `LanguageModel`.\n",
    "        \"\"\"\n",
    "        ### Begin your code\n",
    "\n",
    "        ### End your code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45a2e82",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273c3491",
   "metadata": {
    "id": "273c3491"
   },
   "outputs": [],
   "source": [
    "# Make sure your implementation passes the following sanity checks\n",
    "# Note: Constructing the language model could take 30 seconds or longer\n",
    "# We suggest using `tqdm` to track progress in your `LanguageModel.__init__` function.\n",
    "lm = LanguageModel()\n",
    "\n",
    "print('num. unigrams(\"{}\")'.format(len(lm.unigram_counts))) \n",
    "print('num. bigrams(\"{}\")'.format(len(lm.bigram_counts)))\n",
    "print('num. tokens(\"{}\")'.format(lm.total_num_tokens))\n",
    "\n",
    "\n",
    "# Test a reasonable query with and without typos (you should try your own)!\n",
    "query_wo_typo = \"sharif university\" # write a query without typo\n",
    "query_w_typo = \"sharaf universit\"  # write a query with typo\n",
    "\n",
    "p_wo_typo = math.exp(lm.get_query_logp(query_wo_typo))\n",
    "p_w_typo = math.exp(lm.get_query_logp(query_w_typo))\n",
    "print('P(\"{}\") == {}'.format(query_wo_typo, p_wo_typo))\n",
    "print('P(\"{}\") == {}'.format(query_w_typo, p_w_typo))\n",
    "if p_wo_typo <= p_w_typo:\n",
    "    print('Are you sure \"{}\" should be assigned higher probability than \"{}\"?'\n",
    "          .format(query_w_typo, query_wo_typo))\n",
    "    \n",
    "print(\"done!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbed225",
   "metadata": {
    "id": "4cbed225"
   },
   "source": [
    "<div dir=\"rtl\">\n",
    "\n",
    "### IV.2.  مدل احتمال ویرایش (Edit Probability Model)\n",
    "\n",
    "مدل احتمال ویرایش تلاش می‌کند تا مقدار $P(R\\mid Q)$ را محاسبه کند. برای یک کوئری نامزد ثابت $Q$، مدل احتمال ویرایش احتمالی را حساب می‌کند که یک کوئری خام احتمالا خطادار $R$ ثبت شده است. در این‌جا فاصله‌ی بین کوئری نامزد $Q$ و ورودی $R$ را با استفاده از [فاصله‌ی Damerau-Levenshtein](https://en.wikipedia.org/wiki/Damerau%E2%80%93Levenshtein_distance) مقداردهی می‌کنیم. در فاصله‌ی Damerau-Levenshtein، ویرایش‌های احتمالی برابرthe possible edits are **درج**، **حذف**، **جایگزینی** و **جابجایی**، که هرکدام شامل تک‌کرکترها به عنوان عملگر هستند. در پایین یک کلاس پایه برای `EditCostModel` را می‌بینید."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "786b119e",
   "metadata": {
    "id": "786b119e"
   },
   "outputs": [],
   "source": [
    "\n",
    "class BaseEditProbabilityModel:\n",
    "    def get_edit_logp(self, edited, original):\n",
    "        \"\"\"Gets the log-probability of editing `original` to arrive at `edited`.\n",
    "        The `original` and `edited` arguments are both single terms that are at\n",
    "        most one edit apart.\n",
    "        \n",
    "        Note: The order of the arguments is chosen so that it reads like an\n",
    "        assignment expression:\n",
    "            > edited := EDIT_FUNCTION(original)\n",
    "        or, alternatively, you can think of it as a (unnormalized) conditional probability:\n",
    "            > log P(edited | original)\n",
    "\n",
    "        Args:\n",
    "            edited (str): Edited term.\n",
    "            original (str): Original term.\n",
    "\n",
    "        Returns:\n",
    "            logp (float): Log-probability of `edited` given `original`\n",
    "                under this `EditProbabilityModel`.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError  # Force subclass to implement this method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31bbaba",
   "metadata": {
    "id": "b31bbaba"
   },
   "source": [
    "<div dir=\"rtl\">\n",
    "\n",
    "**نکته مهمی که باید بدانیم این‌است که تابع get_edit_logp با دو ورودی صدا زده می شود که edit-distance آنها یک است.** \n",
    "<br>همچنین خروجی نیازی به نرمال شدن ندارد که مجموع احتمالات کانید‌ها یک شود.\n",
    "\n",
    "</div>\n",
    "\n",
    "```python\n",
    "epm = EditProbabilityModelSubclass(...)  # You will define such a subclass later\n",
    "original = 'user'\n",
    "edited = 'usre'                      # Edited by transposing 'r' and 'e'\n",
    "score = epm.get_edit_logp(edited, original)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dd0c23",
   "metadata": {
    "id": "46dd0c23"
   },
   "source": [
    "<div dir=\"rtl\">\n",
    "\n",
    "#### IV.2.1. مدل ویرایش Uniform-Cost\n",
    "\n",
    "ابتدا *uniform-cost edit model* را پیاده‌سازی می‌کنیم. این مدل محاسبه‌ی احتمال ویرایش را با فرض این که هر ویرایش در فاصله‌ی Damerau-Levenshtein احتمال یکسان دارد، ساده می‌کند. شما باید یک بازه از مقادیر را برای احتمال ویرایش uniform امتحان کنید، اما برای شروع، بازه‌ی 0.01 - 0.10 مناسب است. یک نکته‌ی مهم که باید در ساختن مدل خود به خاطر داشته باشید، این است که کوئری ورودی $R$ کاربر در اکثر مواقع صحیح است (*برای مثال،* $R = Q$). بنابراین باید یک احتمال ثابت بالا برای `edited == original` در نظر گرفته شود؛یک بازه‌ی معقول 0.90 - 0.95 است.\n",
    "\n",
    "مدل احتمال ویرایشی که در اینجا می‌سازید، زمانی که نامزدهای تصحیح کوئری را رتبه‌بندی می‌کنید استفاده خواهد شد. تولیدکننده‌ی این نامزدها (که در بخش بعدی توضیح داده شده‌ است) یک ویرایش در هر زمان انجام می‌دهد و هر وقت یک ویرایش در یک ترم انجام می‌دهد، مدل احتمال ویرایش را صدا می‌زند و log-probabilities را برای تغییرات multi-edit جمع می‌کند. بنابراین در این قسمت شما تنها باید احتمال `edited` را با توجه به این که این مورد **حداکثر یک ویرایش تا `original` فاصله دارد** حساب کنید. یعنی در اینجا `get_edit_logp` خیلی ساده خواهد بود.\n",
    "\n",
    "برای پیاده‌سازی مدل ویرایش uniform-cost کلاس زیر را کامل کنید."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eef111c1",
   "metadata": {
    "id": "eef111c1"
   },
   "outputs": [],
   "source": [
    "\n",
    "class UniformEditProbabilityModel(BaseEditProbabilityModel):\n",
    "    def __init__(self, edit_prob=0.05):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            edit_prob (float): Probability of a single edit occurring, where\n",
    "                an edit is an insertion, deletion, substitution, or transposition,\n",
    "                as defined by the Damerau-Levenshtein distance.\n",
    "        \"\"\"\n",
    "        self.edit_prob = edit_prob\n",
    "\n",
    "    def get_edit_logp(self, edited, original):\n",
    "        \"\"\"Gets the log-probability of editing `original` to arrive at `edited`.\n",
    "        The `original` and `edited` arguments are both single terms that are at\n",
    "        most one edit apart.\n",
    "        \n",
    "        Note: The order of the arguments is chosen so that it reads like an\n",
    "        assignment expression:\n",
    "            > edited := EDIT_FUNCTION(original)\n",
    "        or, alternatively, you can think of it as a (unnormalized) conditional probability:\n",
    "            > log P(edited | original)\n",
    "\n",
    "        Args:\n",
    "            edited (str): Edited term.\n",
    "            original (str): Original term.\n",
    "\n",
    "        Returns:\n",
    "            logp (float): Log-probability of `edited` given `original`\n",
    "                under this `EditProbabilityModel`.\n",
    "        \"\"\"\n",
    "        ### Begin your code\n",
    "\n",
    "        ### End your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3a180c",
   "metadata": {
    "id": "4b3a180c"
   },
   "outputs": [],
   "source": [
    "EDIT_PROB = 0.05\n",
    "epm = UniformEditProbabilityModel(edit_prob=EDIT_PROB)\n",
    "\n",
    "# Test a basic edit\n",
    "edited, original = 'usre', 'user'\n",
    "print(math.isclose(epm.get_edit_logp(edited, original), math.log(EDIT_PROB)))\n",
    "\n",
    "# Test a non-edit\n",
    "print( math.isclose(epm.get_edit_logp(original, original), math.log(1. - EDIT_PROB)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d3802a",
   "metadata": {
    "id": "b3d3802a"
   },
   "source": [
    "<div dir=\"rtl\">\n",
    "\n",
    "### IV.3. تولیدکننده‌ی نامزدها \n",
    "\n",
    "تولیدکننده‌ی نامزدها یک کوئری خام $R$ که توسط کاربر ثبت شده است را می‌گیرد و برای کوئری مورد نظر $Q$ نامزدها را تولید می‌کند. از آن‌جایی که می‌دانیم بیشتر از 97% خطاهای املایی در یک فاصله ویرایش ۲ از کوئری موردنظر کاربر قرار دارند، پیشنهاد می‌شود اصلاح کوئری‌های موجود در این فاصله را از $R$ در نظر بگیرید. این راه‌حلی است که توسط Peter Norvig در [این مقاله در مورد اصلاح خطاهای املایی](http://norvig.com/spell-correct.html) پیشنهاد شده است. اگرچه استفاده از یک تولیدکننده‌ی بروت فورس خالص که تمام رشته‌های ممکن با فاصله‌ی ۲ از  $R$ را تولید کند راه معقولی نیست، چون برای هر $R$ با طول غیرناچیز، تعداد نامزدها خیلی زیاد خواهد شد. بنابراین ما باید مدل احتمال زبان و ویرایش را برای تعداد زیادی از نامزدها محاسبه کنیم.\n",
    "\n",
    "#### IV.3.1. تولیدکننده‌ی نامزدها با فضای جستجوی محدود (Candidate Generator with Restricted Search Space)\n",
    "\n",
    "ما می‌توانیم راه‌حل ساده‌ای را پیش بگیریم که با محدود کردن زیاد فضای جستجو در حین تولید کردن نامزدها قابل مدیریت است. راه‌حل‌های معتبر زیادی برای تولید نامزد بهینه وجود دارد، چند ایده‌ی ساده در زیر آمده:\n",
    "  - با بررسی *هر ترم، جداگانه* در رشته کوئری $R$ شروع کنید و تمام ویرایش‌های ممکن که با فاصله ۱ از آن‌ ترم وجود دارند را در نظر بگیرید.\n",
    "  - به یاد داشته باشید که می‌توانید هایفن‌ها (علامت خط تیره) یا اسپیس‌ها را به عنوان عناصر مجموعه‌ی کرکترهای خود در نظر بگیرید. با این کار می‌توانید تعدادی خطای نسبتا رایج را در نظر بگیرید، برای مثال وقتی در میان یک کلمه به اشتباه فاصله می‌افتد یا زمانی که دو ترم در یک کوئری به اشتباه توسط اسپیس جدا می‌شوند و در واقع باید به هم چسبیده باشند.\n",
    "  - هر وقت برای یک ترم ویرایشی را اعمال می‌کنید، مطمئن شوید که ترم ویرایش شده در دیکشنری ظاهر شود. (به خاطر داشته باشید که فرض کردیم تمام لغات در یک کوئری نامزد معتبر در training corpus ما قابل یافت است).\n",
    "  - اگر ویرایش‌های ممکن برای چندترم جدا را تولید کردید، محصول کارتزین این ترم‌ها را برای تولید یک کوئری نامزد کامل که شامل ویرایش‌های چندین ترم است را در نظر بگیرید. (اما فراموش نکنید که فاصله ویرایش شما برای کل کوئری جمعا نباید از ۲ بیشتر شود).\n",
    "  \n",
    "استراتژی‌های ذکر شده در بالا فقط در حد ایده‌ی اولیه‌ هستند و می‌توانند تا مقدار زیادی گسترش یابند یا تغییر کنند. پیشنهاد می‌کنیم چند گزینه‌ی مختلف را بررسی کنید و در گزارش کتبی خود استراتژی نهایی خود را ذکر کنید و این که چگونه کاربری این استراتژی را به مقدار بهینه رساندید. در نظر داشته باشید که **راه‌حل‌هایی که تمام کوئری‌های نامزد در فاصله‌ی مورد نظر را تولید می‌کنند بسیار کند هستند و نمره‌ی کامل نخواهند داشت.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557738fe",
   "metadata": {
    "id": "557738fe"
   },
   "outputs": [],
   "source": [
    "\n",
    "class CandidateGenerator:\n",
    "    # Alphabet to use for insertion and substitution\n",
    "    alphabet = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm',\n",
    "                'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z',\n",
    "                '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
    "                ' ', ',', '.', '-']\n",
    "\n",
    "    def __init__(self, lm, epm):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            lm (LanguageModel): Language model to use for prior probabilities, P(Q).\n",
    "            epm (EditProbabilityModel): Edit probability model to use for P(R|Q).\n",
    "        \"\"\"\n",
    "        self.lm = lm\n",
    "        self.epm = epm\n",
    "\n",
    "    def get_num_oov(self, query):\n",
    "        \"\"\"Get the number of out-of-vocabulary (OOV) words in `query`.\"\"\"\n",
    "        return sum(1 for w in query.strip().split()\n",
    "                   if w not in self.lm.unigram_counts)\n",
    "\n",
    "    def filter_and_yield(self, query, lp):\n",
    "        if query.strip() and self.get_num_oov(query) == 0:\n",
    "            yield query, lp\n",
    "\n",
    "    def get_candidates(self, query):\n",
    "        \"\"\"Starts from `query`, and performs EDITS OF DISTANCE <=2 to get new\n",
    "        candidate queries. To make scoring tractable, only returns/yields\n",
    "        candidates that satisfy certain criteria (ideas for such criteria are\n",
    "        described in bullet points above).\n",
    "\n",
    "        Hint: We suggest you implement a helper function that takes a term and\n",
    "            generates all possible edits of distance one from that term.\n",
    "            It should probably only return edits that are in the vocabulary\n",
    "            (i.e., edits for which `self.get_num_oov(edited) == 0`).\n",
    "\n",
    "        Args:\n",
    "            query (str): Starting query.\n",
    "\n",
    "        Returns:\n",
    "            Iterable over tuples (cdt, cdt_edit_logp) of candidates and\n",
    "                their associated edit log-probabilities. Return value could be\n",
    "                a list or a generator yielding tuples of this form.\n",
    "        \"\"\"\n",
    "        # Yield the unedited query first\n",
    "        # We provide this line as an example of how to use `self.filter_and_yield`\n",
    "        yield from self.filter_and_yield(query, self.epm.get_edit_logp(query, query))\n",
    "\n",
    "        ### Begin your code\n",
    "\n",
    "        ### End your code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13df394",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "    می‌توانید تست هایی علاوه بر تست زیر برای ارزیابی اضافه \n",
    "    کنید"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f599f01",
   "metadata": {
    "id": "0f599f01"
   },
   "outputs": [],
   "source": [
    "cg = CandidateGenerator(lm, epm)\n",
    "query = 'sharif university'\n",
    "num_candidates = 0\n",
    "did_generate_original = False\n",
    "for candidate, candidate_logp in cg.get_candidates(query):\n",
    "    num_candidates += 1\n",
    "    if candidate == query:\n",
    "        did_generate_original = True\n",
    "        \n",
    "    if cg.get_num_oov(query) != 0:\n",
    "        print(\"You should not generate queries with out-of-vocab terms ('{}' has OOV terms)\".format(candidate))\n",
    "\n",
    "\n",
    "print(num_candidates)\n",
    "print(did_generate_original)\n",
    "### Begin your code\n",
    "\n",
    "### End your code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b629c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2076f83",
   "metadata": {
    "id": "c2076f83"
   },
   "source": [
    "<div dir='rtl'>\n",
    "\n",
    "\n",
    "### IV.4. امتیازدهنده‌ی نامزدها\n",
    "\n",
    "وظیفه امتیازدهنده‌ی نامزدها این است که شبیه‌ترین کوئری $Q$ را به R پیداکند. این‌کار را با ترکیب مدل زبانی  $P(Q)$ و مدل احتمال ویرایش برای $P(R\\mid Q)$ و تولید‌کننده‌ی نامزدها انجام می‌دهد.\n",
    "$$\n",
    "    Q^{*} = \\arg\\max_{Q_{i}} P(Q_{i}\\mid R) = \\arg\\max_{Q_{i}} P(R\\mid Q_{i}) P(Q_{i}),\n",
    "$$\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4fd5e0",
   "metadata": {
    "id": "6e4fd5e0"
   },
   "source": [
    "<div dir=\"rtl\">\n",
    "\n",
    "\n",
    "#### IV.4.1. امتیازدهنده‌ی نامزدها با وزن‌دهی (Candidate Scorer with Weighting)\n",
    "\n",
    "\n",
    "بعد از انجام این ترکیب، ما از یک پارامتر برای وزن‌دادن جداگانه به این دومدل استفاده می‌کنیم.\n",
    "$$\n",
    "    P(Q\\mid R)\\propto P(R\\mid Q)P(Q)^{\\mu}.\n",
    "$$\n",
    "با $\\mu = 1$ شروع کرده و بعدا مقادیر مختلفی را امتحان کنید تا بهترین نتیجه را بگیرید.\n",
    "کد پایین را کامل کنید تا مصحح غلط املایی با uniform edit cost model ساخته شود \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2de033e",
   "metadata": {
    "id": "c2de033e"
   },
   "outputs": [],
   "source": [
    "\n",
    "class CandidateScorer:\n",
    "    \"\"\"Combines the `LanguageModel`, `EditProbabilityModel`, and\n",
    "    `CandidateGenerator` to produce the most likely query Q given a raw query R.\n",
    "    Since the candidate generator already uses the edit probability model, we\n",
    "    do not need to take the edit probability model as an argument in the constructor.\n",
    "    \"\"\"\n",
    "    def __init__(self, lm, cg, mu=1.):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            lm (LanguageModel): Language model for estimating P(Q).\n",
    "            cg (CandidateGenerator): Candidate generator for generating possible Q.\n",
    "            mu (float): Weighting factor for the language model (see write-up).\n",
    "                Remember that our probability computations are done in log-space.\n",
    "        \"\"\"\n",
    "        self.lm = lm\n",
    "        self.cg = cg\n",
    "        self.mu = mu\n",
    "\n",
    "    def get_score(self, query, log_edit_prob):\n",
    "        \"\"\"Uses the language model and `log_edit_prob` to compute the final\n",
    "        score for a candidate `query`. Uses `mu` as weighting exponent for P(Q).\n",
    "\n",
    "        Args:\n",
    "            query (str): Candidate query.\n",
    "            log_edit_prob (float): Log-probability of candidate query given\n",
    "                original query (i.e., log(P(R|Q), where R is `query`).\n",
    "\n",
    "        Returns:\n",
    "            log_p (float): Final score for the query, i.e., the log-probability\n",
    "                of the query.\n",
    "        \"\"\"\n",
    "        ### Begin your code\n",
    "\n",
    "        ### End your code\n",
    "\n",
    "    def correct_spelling(self, r):\n",
    "        \"\"\"Corrects spelling of raw query `r` to get the intended query `q`.\n",
    "\n",
    "        Args:\n",
    "            r (str): Raw input query from the user.\n",
    "\n",
    "        Returns:\n",
    "            q (str): Spell-corrected query. That is, the query that maximizes\n",
    "                P(R|Q)*P(Q) under the language model and edit probability model,\n",
    "                restricted to Q's generated by the candidate generator.\n",
    "        \"\"\"\n",
    "        ### Begin your code\n",
    "\n",
    "        ### End your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174eb40e",
   "metadata": {
    "id": "174eb40e"
   },
   "outputs": [],
   "source": [
    "# Assumes LanguageModel lm was already built above\n",
    "print('Building edit probability model...')\n",
    "epm = UniformEditProbabilityModel()\n",
    "print('Building candidate generator...')\n",
    "cg = CandidateGenerator(lm, epm)\n",
    "print('Building candidate scorer model...')\n",
    "cs = CandidateScorer(lm, cg, mu=1.0)\n",
    "print('Running spelling corrector...')\n",
    "\n",
    "# Add your own queries here to test your spelling corrector\n",
    "queries = [('sharaf university', ' sharif university'),\n",
    "           ('sharif university', ' sharif university')\n",
    "           ]\n",
    "for query, expected in queries:\n",
    "    corrected = cs.correct_spelling(query)\n",
    "    print(\"\\t'{}' corrected to '{}'\".format(query, corrected))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cf3de1",
   "metadata": {
    "id": "a1cf3de1"
   },
   "source": [
    "#### IV.4.2. Dev Set Evaluation (Uniform)\n",
    "\n",
    "</div>\n",
    "\n",
    "<div dir=\"rtl\">\n",
    "حال ما یک تصحیح‌گر غلط املایی اولیه را ساختیم.\n",
    "برای ارزیابی مدل خود, سل‌های زیر را اجرا کنید (در صورت داشتن دقت بالاتر از ۸۲٪, حداقل ۵ و حداکثر ۱۵درصد نمره امتیازی به شما داده می‌شود(در صورتی که گروه‌های کمی به این دقت رسیدند, نمره امتیازی به صورت رقابتی داده‌خواهد شد)). \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05b2639",
   "metadata": {
    "id": "b05b2639"
   },
   "outputs": [],
   "source": [
    "def dev_eval(candidate_scorer, verbose=False):\n",
    "    \"\"\"Evaluate `candidate_scorer` on the dev set.\"\"\"\n",
    "    query_num = 1\n",
    "    yours_correct = 0\n",
    "    google_correct = 0\n",
    "    # Read originals, ground-truths, Google's predictions\n",
    "    dev_dir = 'MIR2-data/dev_set/'\n",
    "    with tqdm(total=455, unit=' queries') as pbar, \\\n",
    "            open(os.path.join(dev_dir, 'queries.txt'), 'r') as query_fh, \\\n",
    "            open(os.path.join(dev_dir, 'gold.txt'), 'r') as gold_fh, \\\n",
    "            open(os.path.join(dev_dir, 'google.txt'), 'r') as google_fh:\n",
    "        while True:\n",
    "            # Read one line\n",
    "            query = query_fh.readline().rstrip('\\n')\n",
    "            if not query:\n",
    "                # Finished all queries\n",
    "                break\n",
    "            corrected = candidate_scorer.correct_spelling(query)\n",
    "            corrected = ' '.join(corrected.split())  # Squash multiple spaces\n",
    "            gold = gold_fh.readline().rstrip('\\n')\n",
    "            google = google_fh.readline().rstrip('\\n')\n",
    "\n",
    "            # Count whether correct\n",
    "            if corrected == gold:\n",
    "                yours_correct += 1\n",
    "            if google == gold:\n",
    "                google_correct += 1\n",
    "\n",
    "            # Print running stats\n",
    "            yours_accuracy = yours_correct / query_num * 100\n",
    "            google_accuracy = google_correct / query_num * 100\n",
    "            if verbose:\n",
    "                print('QUERY {:03d}'.format(query_num))\n",
    "                print('---------')\n",
    "                print('(original):      {}'.format(query))\n",
    "                print('(corrected):     {}'.format(corrected))\n",
    "                print('(google):        {}'.format(google))\n",
    "                print('(gold):          {}'.format(gold))\n",
    "                print('Google accuracy: {}/{} ({:5.2f}%)\\n'\n",
    "                      .format(google_correct, query_num, google_accuracy))\n",
    "                print('Your accuracy:   {}/{} ({:5.2f}%)'\n",
    "                      .format(yours_correct, query_num, yours_accuracy))\n",
    "            \n",
    "            pbar.set_postfix(google='{:5.2f}%'.format(google_accuracy),\n",
    "                             yours='{:5.2f}%'.format(yours_accuracy))\n",
    "            pbar.update()\n",
    "            query_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dc5ee2",
   "metadata": {
    "id": "85dc5ee2"
   },
   "outputs": [],
   "source": [
    "# Set verbose=True for debugging output\n",
    "dev_eval(cs, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ed4a81",
   "metadata": {
    "id": "55ed4a81"
   },
   "source": [
    "<a id='empirical'></a>\n",
    "<div dir=\"rtl\">\n",
    "\n",
    "\n",
    "##  تصحیح املا با هزینه‌های ویرایش تجربی (امتیازی ۲۰ درصد)\n",
    "\n",
    "### V.1. مدل احتمال ویرایش بهبودیافته (Improved Edit Probability Model)\n",
    "\n",
    "\n",
    "</div>\n",
    "<div dir='rtl'>\n",
    "حال که تصحیح‌کننده غلط املایی ما با یک مدل احتمالاتی ویرایش اولیه(edit probability model) به درستی کار می‌کند, برای ویرایش احتمالات به سمت یک رویکرد کاربردی‌تر می‌رویم. برای این بخش و learn کردن این احتمال ویرایش‌ها ما از داده‌ی خطای تجربی که در  \n",
    "`data/training_set/edit1s.txt` قراردارد استفاده می‌کنیم\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0d9ccb",
   "metadata": {
    "id": "af0d9ccb"
   },
   "source": [
    "<div dir='rtl'>\n",
    "\n",
    "#### V.1.1. هزینه‌ها‌ی ویرایش تجربی (Empirical Edit Costs) \n",
    "</div>\n",
    "\n",
    "<div dir='rtl'>\n",
    "\n",
    "\n",
    "\n",
    "یک لیست از جفت کوئری‌هایی که فاصله‌یشان از یکدیگر دقیقا ۱ است به شما داده شده است. در قدم اول یک الگوریتم ساده برای تعیین کردن این که کدام ویرایش بخصوص میان دو کوئری در هر جفت وجود دارد پیاده‌سازی کنید. با جمع کردن شمارش تمام ویرایش‌های این‌چنینی در تمام کوئری‌ها احتمال هر ویرایش قابل محاسبه خواهد بود. به عنوان مثال، اگر خواستید تعیین کنید که احتمال جایگزین شدن اشتباهی حرف 'e' با حرف 'a' در یک کوئری چقدر است، باید مقدار زیر را محاسبه کنید:\n",
    "$$\n",
    "    P(\\texttt{sub}[a, e]) = \\frac{\\texttt{count}(\\texttt{sub}[a, e])}{\\texttt{count}(e)}.\n",
    "$$\n",
    "با توجه به این که احتمال عملیات‌های درج و حذف به حروف قبل از حرفی که روی آن عملی انجام می‌شود مشروطند، پس باید راه‌حل مناسبی برای حذف و درج در ابتدای یک لغت ارائه دهید. در نهایت برای رفع مشکل پراکندگی داده‌ها در فایل training روش هموارسازی Laplace add-one را برای احتمالات ویرایش پیاده‌سازی کنید."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99ccb999",
   "metadata": {
    "id": "99ccb999"
   },
   "outputs": [],
   "source": [
    "\n",
    "class Edit:\n",
    "    \"\"\"Represents a single edit in Damerau-Levenshtein distance.\n",
    "    We use this class to count occurrences of different edits in the training data.\n",
    "    \"\"\"\n",
    "    INSERTION = 1\n",
    "    DELETION = 2\n",
    "    TRANSPOSITION = 3\n",
    "    SUBSTITUTION = 4\n",
    "\n",
    "    def __init__(self, edit_type, c1=None, c2=None):\n",
    "        \"\"\"\n",
    "        Members:\n",
    "            edit_type (int): One of Edit.{NO_EDIT,INSERTION,DELETION,\n",
    "                TRANSPOSITION,SUBSTITUTION}.\n",
    "            c1 (str): First (in original) char involved in the edit.\n",
    "            c2 (str): Second (in original) char involved in the edit.\n",
    "        \"\"\"\n",
    "        self.edit_type = edit_type\n",
    "        self.c1 = c1\n",
    "        self.c2 = c2\n",
    "\n",
    "\n",
    "class EmpiricalEditProbabilityModel(BaseEditProbabilityModel):\n",
    "\n",
    "    START_CHAR = ''      # Used to indicate start-of-query\n",
    "    NO_EDIT_PROB = 0.92  # Hyperparameter for probability assigned to no-edit\n",
    "\n",
    "    def __init__(self, training_set_path='MIR2-data/training_set/edit1s.txt'):\n",
    "        \"\"\"Builds the necessary data structures to compute log-probabilities of\n",
    "        distance-1 edits in constant time. In particular, counts the unigrams\n",
    "        (single characters), bigrams (of 2 characters), alphabet size, and\n",
    "        edit count for insertions, deletions, substitutions, and transpositions.\n",
    "\n",
    "        Hint: Use the `Edit` class above. It may be easier to write the `get_edit`\n",
    "        function first, since you should call that function here.\n",
    "\n",
    "        Note: We suggest using tqdm with the size of the training set (819722) to track\n",
    "        the initializers progress when parsing the training set file.\n",
    "\n",
    "        Args:\n",
    "            training_set_path (str): Path to training set of empirical error data.\n",
    "        \"\"\"\n",
    "        # Your code needs to initialize all four of these data structures\n",
    "        self.unigram_counts = Counter()  # Maps chars c1 -> count(c1)\n",
    "        self.bigram_counts = Counter()   # Maps tuples (c1, c2) -> count((c1, c2))\n",
    "        self.alphabet_size = 0           # Counts all possible characters\n",
    "\n",
    "        # Maps edit-types -> dict mapping tuples (c1, c2) -> count(edit[c1, c2])\n",
    "        # Example usage: \n",
    "        #   > e = Edit(Edit.SUBSTITUTION, 'a', 'b')\n",
    "        #   > edit_count = self.edit_counts[e.edit_type][(e.c1, e.c2)]\n",
    "        self.edit_counts = {edit_type: Counter()\n",
    "                            for edit_type in (Edit.INSERTION, Edit.DELETION,\n",
    "                                              Edit.SUBSTITUTION, Edit.TRANSPOSITION)}\n",
    "\n",
    "        with open(training_set_path, 'r') as training_set:\n",
    "            for example in tqdm(training_set, total=819722):\n",
    "                edited, original = example.strip().split('\\t')\n",
    "\n",
    "                ### Begin your code\n",
    "\n",
    "                ### End your code\n",
    "\n",
    "    def get_edit(self, edited, original):\n",
    "        \"\"\"Gets an `Edit` object describing the type of edit performed on `original`\n",
    "        to produce `edited`.\n",
    "\n",
    "        Note: Only edits with an edit distance of at most 1 are valid inputs.\n",
    "\n",
    "        Args:\n",
    "            edited (str): Raw query, which contains exactly one edit from `original`.\n",
    "            original (str): True query. Want to find the edit which turns this into `edited`.\n",
    "\n",
    "        Returns:\n",
    "            edit (Edit): `Edit` object representing the edit to apply to `original` to get `edited`.\n",
    "                If `edited == original`, returns None.\n",
    "        \"\"\"\n",
    "        ### Begin your code\n",
    "\n",
    "        ### End your code\n",
    "\n",
    "    def get_edit_logp(self, edited, original):\n",
    "        \"\"\"Gets the log-probability of editing `original` to arrive at `edited`.\n",
    "        The `original` and `edited` arguments are both single terms that are at\n",
    "        most one edit apart.\n",
    "        \n",
    "        Note: The order of the arguments is chosen so that it reads like an\n",
    "        assignment expression:\n",
    "            > edited := EDIT_FUNCTION(original)\n",
    "        or, alternatively, you can think of it as a (unnormalized) conditional probability:\n",
    "            > log P(edited | original)\n",
    "\n",
    "        Args:\n",
    "            edited (str): Edited term.\n",
    "            original (str): Original term.\n",
    "\n",
    "        Returns:\n",
    "            logp (float): Log-probability of `edited` given `original`\n",
    "                under this `EditProbabilityModel`.\n",
    "        \"\"\"\n",
    "        ### Begin your code\n",
    "\n",
    "        ### End your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6159e772",
   "metadata": {
    "id": "6159e772"
   },
   "outputs": [],
   "source": [
    "# Build spelling corrector for evaluation on the dev set\n",
    "lm = LanguageModel()\n",
    "epm = EmpiricalEditProbabilityModel()\n",
    "cg = CandidateGenerator(lm, epm)\n",
    "cs = CandidateScorer(lm, cg, mu=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92745d20",
   "metadata": {},
   "source": [
    "<div dir='rtl'>\n",
    "     . در صورت داشتن دقت بالاتر از ۸۱٪, ۵ تا ۱۵درصد نمره امتیازی به شما داده می‌شود (در صورتی که گروه‌های کمی به این دقت رسیدند, نمره امتیازی به صورت رقابتی داده‌خواهد شد)\n",
    "    </div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890f3261",
   "metadata": {
    "id": "890f3261"
   },
   "outputs": [],
   "source": [
    "# Set verbose=True for debugging output\n",
    "dev_eval(cs, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25006ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88c3a3c5",
   "metadata": {},
   "source": [
    "<a id='written'></a>\n",
    "<div dir=\"rtl\">\n",
    "\n",
    "\n",
    "##  گزارش مکتوب\n",
    "\n",
    "\n",
    "\n",
    "</div>\n",
    "\n",
    "<div dir=\"rtl\">\n",
    "\n",
    "\n",
    "در این بخش انتظار می‌رود که شما گزارشی از کارهای انجام شده در هر تسک - نتایج گرفته شده و ایده‌هایی که استفاده کردید و نیز تغییرات داده شده در کد(در صورت وجود) بنویسید. این بخش ۱۵درصد نمره شما را خواهد داشت\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953dc160",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MIR-Phase2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "7812ea015bdcee6f23a998adcdd2ef97c151c0c241b7b7070987d9313e41299d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
