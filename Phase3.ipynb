{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:300%;\">\n",
    "<font face=\"XB Zar\" size=5>\n",
    "<div align=center>\n",
    "    <font size=6>\n",
    "    باسمه تعالی\n",
    "    </font>\n",
    "    <br><br>\n",
    "    <font>\n",
    "    درس بازیابی پیشرفته اطلاعات\n",
    "    <br>\n",
    "        <font size=3>\n",
    "            مدرس: دکتر لشکری\n",
    "        </font>\n",
    "    </font>\n",
    "    <br><br>\n",
    "    <font>\n",
    "        <b>فاز سوم پروژه</b>\n",
    "    </font>\n",
    "    <br>\n",
    "    <font size=3>\n",
    "    موعد تحویل: ۱۵ بهمن ۱۴۰۰\n",
    "    </font>\n",
    "    <br>\n",
    "    <font size=4>\n",
    "    دستیاران آموزشی:\n",
    "        سجاد فقفورمغربی،\n",
    "        علی بالاپور\n",
    "    </font>\n",
    "    <br>\n",
    "        <font size=2>\n",
    "        دانشگاه صنعتی شریف\n",
    "        <br>\n",
    "        دانشکده مهندسی کامپیوتر\n",
    "    </font>\n",
    "</div>\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:200%;\">\n",
    "<font face=\"XB Zar\" size=3>\n",
    "    <div align=center>\n",
    "        <b>نام اعضای گروه</b>: \n",
    "        <br>\n",
    "        <b>شماره‌ی دانشجویی اعضای گروه</b>: \n",
    "        <br>\n",
    "    </div>\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align= \"justify\" dir=\"rtl\">\n",
    "<font face=\"Calibri\" size=4>\n",
    "    <h1>مقدمه</h1>\n",
    "هدف این پروژه پیاده‌سازی الگوریتم‌های طبقه‌بندی و خوشه‌بندی، طراحی خزنده، و ارزش‌گذاری مقالات و رتبه‌بندی نویسنده‌ها بر اساس اطلاعات جمع‌آوری‌شده توسط خزنده است. <br>\n",
    "برای انجام این پروژه، نکات زیر را در نظر داشته باشید:\n",
    "    <ul>\n",
    "        <li> انجام این فاز از پروژه به صورت گروهی می‌باشد.</li>\n",
    "        <li>تمامی پیاده‌سازی‌ها باید با زبان پایتون صورت گیرند.</li>\n",
    "        <li>محدودیت استفاده از کتاب‌خانه‌های آماده در هر بخش مشخص شده است.</li>\n",
    "        <li>توجه داشته باشید که خروجی و دقت مدل‌ها، خروجی اطلاعات crawler و ... تأثیری در ارزیابی این فاز از پروژه ندارند و ارزشیابی صرفاً بر اساس پیاده‌سازی درست موارد خواسته‌شده می‌باشد.\n",
    "</li>\n",
    "        <li>در مجموع این پروژه 130 نمره بوده که 30 نمره از آن امتیازی می‌باشد.</li>\n",
    "    </ul>\n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align= \"justify\" dir=\"rtl\">\n",
    "<font face=\"Calibri\" size=4>\n",
    "    <h1>طبقه‌بندی و خوشه‌بندی (50 + 20 نمره)</h1>\n",
    "    در این بخش از پروژه قصد داریم طبقه‌بندی و خوشه‌بندی را روی داده‌های متنی موجود در دیتاست \n",
    "    <a href='https://www.kaggle.com/amananandrai/ag-news-classification-dataset?select=train.csv'>AG News</a>\n",
    "    انجام دهیم. این دیتاست شامل 120000 نمونه در داده آموزش و 7600 نمونه در داده تست می‌باشد. برای این قسمت پروژه، تنها از 10 درصد داده‌های دیتاست آموزش، استفاده می‌گردد و از تمامی داده‌های دیتاست تست، برای بررسی عملکرد مدل‌ها استفاده می‌شود. <br>\n",
    "    داده‌های این دیتاست از سه بخش تشکیل شده‌اند: عنوان خبر، متن خبر، و دسته‌ی خبر.<br>\n",
    "    داده‌ها (خبرها) در این دیتاست 4 دسته می‌باشند که این دسته‌ها به‌صورت زیرند:\n",
    "<ul>\n",
    "  <li>World : 0</li>\n",
    "  <li>Sports : 1</li>\n",
    "  <li>Business : 2</li>\n",
    "  <li>Sci/Tech : 3</li>\n",
    "</ul>\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align= \"justify\" dir=\"rtl\">\n",
    "<font face=\"Calibri\" size=4>\n",
    "    <h2>آماده‌سازی داده</h2>\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "8kb1pQ_4YNQ-"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "YaZMIDyqYNRI"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/train.csv', index_col=0)\n",
    "test_df = pd.read_csv('data/test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Oil and Economy Cloud Stocks' Outlook</td>\n",
       "      <td>NEW YORK (Reuters) - Soaring crude prices plu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Saudi Arabia to open up oil taps</td>\n",
       "      <td>Saudi Arabia says it is ready to push an extra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Quality Gets Swept Away</td>\n",
       "      <td>Quality Distribution is hammered after reporti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>More Big Boobs in Playboy</td>\n",
       "      <td>An interview with Google's co-founders due out...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Paid Search Growth May Slow</td>\n",
       "      <td>A new Internet advertising forecast shows a sl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                  title  \\\n",
       "0      2  Oil and Economy Cloud Stocks' Outlook   \n",
       "1      2       Saudi Arabia to open up oil taps   \n",
       "2      2                Quality Gets Swept Away   \n",
       "3      2              More Big Boobs in Playboy   \n",
       "4      2            Paid Search Growth May Slow   \n",
       "\n",
       "                                         description  \n",
       "0   NEW YORK (Reuters) - Soaring crude prices plu...  \n",
       "1  Saudi Arabia says it is ready to push an extra...  \n",
       "2  Quality Distribution is hammered after reporti...  \n",
       "3  An interview with Google's co-founders due out...  \n",
       "4  A new Internet advertising forecast shows a sl...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Fears for T N pension after talks</td>\n",
       "      <td>Unions representing workers at Turner   Newall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>The Race is On: Second Private Team Sets Launc...</td>\n",
       "      <td>SPACE.com - TORONTO, Canada -- A second\\team o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Ky. Company Wins Grant to Study Peptides (AP)</td>\n",
       "      <td>AP - A company founded by a chemistry research...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Prediction Unit Helps Forecast Wildfires (AP)</td>\n",
       "      <td>AP - It's barely dawn when Mike Fitzpatrick st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Calif. Aims to Limit Farm-Related Smog (AP)</td>\n",
       "      <td>AP - Southern California's smog-fighting agenc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                              title  \\\n",
       "0      2                  Fears for T N pension after talks   \n",
       "1      3  The Race is On: Second Private Team Sets Launc...   \n",
       "2      3      Ky. Company Wins Grant to Study Peptides (AP)   \n",
       "3      3      Prediction Unit Helps Forecast Wildfires (AP)   \n",
       "4      3        Calif. Aims to Limit Farm-Related Smog (AP)   \n",
       "\n",
       "                                         description  \n",
       "0  Unions representing workers at Turner   Newall...  \n",
       "1  SPACE.com - TORONTO, Canada -- A second\\team o...  \n",
       "2  AP - A company founded by a chemistry research...  \n",
       "3  AP - It's barely dawn when Mike Fitzpatrick st...  \n",
       "4  AP - Southern California's smog-fighting agenc...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FXdKgwswAfrq",
    "outputId": "6d0cce68-8e6d-44e1-e73e-fe8bdd7f7a3b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12105, 7600)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df), len(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align= \"justify\" dir=\"rtl\">\n",
    "<font face=\"Calibri\" size=4>\n",
    "با توجه به اینکه نمی‌توان مدل‌های طبقه‌بندی و خوشه‌بندی را به‌طور مستقیم بر روی داده‌های متنی آموزش داد و آزمود، در ابتدا باید این داده‌ها را به شکل عددی تبدیل کنیم. برای این کار روش‌های مختلفی وجود دارد. یکی از این روش‌ها، استفاده از  الگوریتم tf-idf و اعمال تجزیه SVD (به‌منظور کاهش ابعاد) برای ایجاد embedding متناظر با متن می‌باشد. با استفاده از قطعه کد زیر، عملیات گفته‌شده را اجرا می‌کنیم.     \n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "zh6Ni8r3YNRN"
   },
   "outputs": [],
   "source": [
    "import typing as th\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import Pipeline\n",
    "import string\n",
    "\n",
    "\n",
    "VECTOR_SIZE = 128\n",
    "NUMERICS = ''.join(str(i) for i in range(10))\n",
    "TRANSLATOR = str.maketrans('', '', NUMERICS + string.punctuation)\n",
    "\n",
    "\n",
    "class Preprocessor(BaseEstimator, TransformerMixin):\n",
    "    def init(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, x, y=None, **params):\n",
    "        return self\n",
    "    \n",
    "    def fit_transform(self, x, y=None, **params):\n",
    "        return self.fit(x, y, **params).transform(x)\n",
    "    \n",
    "    def transform(self, x):\n",
    "        x_copy = x.copy()\n",
    "        x_copy['title'] = (x['title'].map(str)).apply(\n",
    "            lambda item: item.translate(TRANSLATOR).lower()                       \n",
    "        )\n",
    "        x_copy['description'] = (x['description'].map(str)).apply(              \n",
    "            lambda item: item.translate(TRANSLATOR).lower()\n",
    "        )\n",
    "        x_copy['combination'] = (x['title'].map(str) + ' ' + x['description'].map(str)).apply(\n",
    "            lambda item: item.translate(TRANSLATOR).lower()                       \n",
    "        )\n",
    "        x_copy['title-split'] = x_copy['title'].apply(lambda item: item.split())                \n",
    "        x_copy['description-split'] = x_copy['description'].apply(lambda item: item.split())\n",
    "        x_copy['combination-split'] = x_copy['combination'].apply(lambda item: item.split())    \n",
    "        return x_copy\n",
    "\n",
    "\n",
    "title_tf_idf_vectorizer = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('pca', TruncatedSVD())\n",
    "])\n",
    "\n",
    "description_tf_idf_vectorizer = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('pca', TruncatedSVD())\n",
    "])\n",
    "\n",
    "combination_tf_idf_vectorizer = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('pca', TruncatedSVD())\n",
    "])\n",
    "\n",
    "\n",
    "class Vectorizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_components=VECTOR_SIZE):\n",
    "        self.n_components = n_components\n",
    "        \n",
    "        # title parameters\n",
    "        self.title_tfidf = dict()\n",
    "        \n",
    "        # description parameters\n",
    "        self.description_tfidf = dict()\n",
    "\n",
    "        # combination parameters\n",
    "        self.combination_tfidf = dict()\n",
    "        \n",
    "        # title vectorizers\n",
    "        self.title_tfidf_vectorizer = title_tf_idf_vectorizer\n",
    "        self.title_tfidf_vectorizer.set_params(**self.title_tfidf)\n",
    "        \n",
    "        # description vectorizers\n",
    "        self.description_tfidf_vectorizer = description_tf_idf_vectorizer\n",
    "        self.description_tfidf_vectorizer.set_params(**self.description_tfidf)\n",
    "\n",
    "        # combination vectorizers\n",
    "        self.combination_tfidf_vectorizer = description_tf_idf_vectorizer\n",
    "        self.combination_tfidf_vectorizer.set_params(**self.description_tfidf)\n",
    "        \n",
    "    def fit(self, x, y=None):\n",
    "        # finalizing title parameters\n",
    "        self.title_tfidf['pca__n_components'] = self.title_tfidf.get('pca__n_components', self.n_components)\n",
    "        self.title_tfidf_vectorizer.set_params(**self.title_tfidf)\n",
    "        \n",
    "        # finalizing description parameters\n",
    "        self.description_tfidf['pca__n_components'] = self.description_tfidf.get('pca__n_components', self.n_components)\n",
    "        self.description_tfidf_vectorizer.set_params(**self.description_tfidf)\n",
    "\n",
    "        # finalizing combination parameters\n",
    "        self.combination_tfidf['pca__n_components'] = self.combination_tfidf.get('pca__n_components', self.n_components)\n",
    "        self.combination_tfidf_vectorizer.set_params(**self.combination_tfidf)\n",
    "        \n",
    "        # fitting models\n",
    "        self.title_tfidf_vectorizer.fit(x['title'])\n",
    "        self.description_tfidf_vectorizer.fit(x['description'])\n",
    "        self.combination_tfidf_vectorizer.fit(x['combination'])\n",
    "        return self\n",
    "\n",
    "    def transform(self, x):\n",
    "        x_copy = x.copy()\n",
    "        x_copy['vec_1'] = self.title_tfidf_vectorizer.transform(x['title']).tolist()\n",
    "        x_copy['vec_2'] = self.description_tfidf_vectorizer.transform(x['description']).tolist()\n",
    "        x_copy['vec_3'] = self.combination_tfidf_vectorizer.transform(x['combination']).tolist()\n",
    "        x_copy = x_copy.drop(columns=['title',\n",
    "                                      'description',\n",
    "                                      'title-split',\n",
    "                                      'description-split',\n",
    "                                      'combination',\n",
    "                                      'combination-split'])\n",
    "        return x_copy\n",
    "\n",
    "    def fit_transform(self, x, y=None, **fit_params):\n",
    "        return self.fit(x, y).transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align= \"justify\" dir=\"rtl\">\n",
    "<font face=\"Calibri\" size=4>\n",
    "قطعه کد بالا، یک دیتافریم جدید با 4 ستون ایجاد می‌کند که این ستون‌ها شامل: برچسب خبر (label)، بردار تولیدشده برای ستون عنوان خبر (vec_1)، بردار تولیدشده برای ستون متن خبر (vec_2)، و بردار تولیدشده برای ترکیب متن و عنوان خبر (vec_3). <br>\n",
    "    برای تولید این دیتافریم، در یک مرحله پیش‌پردازش روی داده‌های متنی دیتافریم ابتدایی انجام می‌شود که شامل case folding، حذف علائم نگارشی و اعداد، و tokenization است. سپس بر روی داده‌های متنی پیش‌پردازش شده، با استفاده از الگوریتم tf-idf و اعمال TruncatedSVD، بردارهای هر داده متنی را تولید می‌نماییم. به‌طور کلی به این روش (تولید بردار با استفاده از tf-idf و SVD) Latent Semantic Analysis گفته می‌شود. برای مطالعه بیشتر می‌توانید \n",
    "    <a href='https://towardsdatascience.com/lovecraft-with-natural-language-processing-part-4-latent-semantic-analysis-70aa2fa2161b'>این</a>\n",
    "    و \n",
    "    <a href='https://mccormickml.com/2016/03/25/lsa-for-text-classification-tutorial/'>این</a>\n",
    "    را بررسی کنید.\n",
    "</font>\n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "id": "TnnXlp7BYNRU",
    "outputId": "41c46a2b-d20c-46b3-b6a5-dabf731c0b7e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>vec_1</th>\n",
       "      <th>vec_2</th>\n",
       "      <th>vec_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>[0.08125294202823238, -0.006680461808614931, 0...</td>\n",
       "      <td>[0.24181055018482536, 0.13462506719424697, 0.0...</td>\n",
       "      <td>[0.2343000105005124, 0.22338559345524414, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[0.15750190948084342, -0.11621429726768015, -0...</td>\n",
       "      <td>[0.16799963685266736, 0.1315699941949885, 0.03...</td>\n",
       "      <td>[0.16055589730315595, 0.17542819044200442, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                              vec_1  \\\n",
       "0      2  [0.08125294202823238, -0.006680461808614931, 0...   \n",
       "1      2  [0.15750190948084342, -0.11621429726768015, -0...   \n",
       "\n",
       "                                               vec_2  \\\n",
       "0  [0.24181055018482536, 0.13462506719424697, 0.0...   \n",
       "1  [0.16799963685266736, 0.1315699941949885, 0.03...   \n",
       "\n",
       "                                               vec_3  \n",
       "0  [0.2343000105005124, 0.22338559345524414, -0.0...  \n",
       "1  [0.16055589730315595, 0.17542819044200442, 0.0...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor = Pipeline(steps=[\n",
    "    ('preprocess', Preprocessor()),\n",
    "    ('vectorizer', Vectorizer())\n",
    "])\n",
    "preprocessor.fit(train_df)\n",
    "train_data = preprocessor.transform(train_df).dropna()\n",
    "test_data = preprocessor.transform(test_df).dropna()\n",
    "\n",
    "train_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align= \"justify\" dir=\"rtl\">\n",
    "<font face=\"Calibri\" size=4>\n",
    "    در این بخش، قسمتی از داده آموزش را جدا کرده و تحت عنوان داده validation ذخیره می‌نماییم. با استفاده از داده validation به اعتبارسنجی عملکرد مدل پرداخته و در انتها، پس از تنظیم مدل از داده تست برای بررسی نهایی عملکرد استفاده می‌نماییم.\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "dKa1d_qBYNRW"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_split, val_split = train_test_split(train_data, test_size=0.1)\n",
    "\n",
    "train_split = train_split.dropna()\n",
    "val_split = val_split.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sldz7NjcYNRZ",
    "outputId": "57f6b6dc-fcda-4f03-cde8-56942c1ad8c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10894, 4), (1211, 4))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_split.shape, val_split.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y7T2uKyRYNRe"
   },
   "source": [
    "<div align= \"justify\" dir=\"rtl\">\n",
    "<font face=\"Calibri\" size=4>\n",
    "    <h2>طبقه‌بندی (30+10 نمره)</h2>\n",
    "    در این بخش سه مدل Naïve Bayes، k-Nearest Neighbors و SVM را بررسی می‌کنیم. به ازای هر یک، در ابتدا مدل را با استفاده از داده train، آموزش داده و سپس با استفاده از داده vaidation، به بررسی کلی عملکرد و تنظیم هایپرپارامتر و ویژگی‌های مدل می‌پردازید و بهترین مدل را با توجه به صحت (accuracy) مدل انتخاب می‌کنید. در بخش ارزیابی به بررسی عملکرد مدل‌های انتخاب‌شده بر روی داده test بر اساس معیارهای گفته‌شده، می‌پردازید. <br>\n",
    "    توجه داشته باشید که به ازای هر خبر، سه نوع embedding متناظر با آن خبر داریم و درنتیجه به ازای هر الگوریتم، باید سه مدل را به عنوان مدل نهایی انتخاب نمایید. یعنی 9 مدل در انتها باید بر روی داده test متناظر بررسی شوند. این مدل‌ها به‌صورت زیر می‌باشند:\n",
    "<ul>\n",
    "    <li>مدل naïve bayes آموزش داده شده روی ستون vec_1 یا embedding حاصل از عنوان خبر</li>\n",
    "    <li>مدل naïve bayes آموزش داده شده روی ستون vec_2 یا embedding حاصل از متن خبر</li>\n",
    "    <li>مدل naïve bayes آموزش داده شده روی ستون vec_3 یا embedding حاصل از ترکیب عنوان و متن خبر</li>\n",
    "    <li>مدل knn آموزش داده شده روی ستون vec_1 یا embedding حاصل از عنوان خبر</li>\n",
    "    <li>مدل knn آموزش داده شده روی ستون vec_2 یا embedding حاصل از متن خبر</li>\n",
    "    <li>مدل knn آموزش داده شده روی ستون vec_3 یا embedding حاصل از ترکیب عنوان و متن خبر</li>\n",
    "    <li>مدل svm  آموزش داده شده روی ستون vec_1 یا embedding حاصل از عنوان خبر</li>\n",
    "    <li>مدل svm آموزش داده شده روی ستون vec_2 یا embedding حاصل از متن خبر</li>\n",
    "    <li>مدل svm آموزش داده شده روی ستون vec_3 یا embedding حاصل از ترکیب عنوان و متن خبر</li>\n",
    "</ul>\n",
    "    \n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TLfm_GzmdJp5"
   },
   "source": [
    "<div align= \"justify\" dir=\"rtl\">\n",
    "<font face=\"Calibri\" size=4>\n",
    "    <h3>الگوریتم Naïve Bayes (8 نمره)</h3>\n",
    "الگوریتم Naïve Bayes را از ابتدا پیاده‌سازی کنید و روی داده train، آموزش دهید. سپس با تنظیمات دلخواه (نوع توزیع استفاده‌شده، مقدار smoothing  و ...) مدل را روی داده validation اعتبارسنجی کرده و مدل را ذخیره کنید. <br>\n",
    "توجه: از کتابخانه‌هایی مانند pandas, numpy و ... برای پیاده‌سازی می‌توانید استفاده کنید. البته این استفاده باید در راستای پیاده‌سازی مدل باشد. یعنی برای مثال  نمی‌توانید از ماژول‌ها و کلاس‌هایی مانند sklearn.naive_bayes.GaussianNB برای این قسمت استفاده کنید! اما استفاده از سایر توابع و کتابخانه‌های sklearn مانند GridSearchCV مجاز می‌باشد (و حتی توصیه می‌گردد).\n",
    "    \n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xF4kFclKYNRg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9W3vmyXDdcwQ"
   },
   "source": [
    "<div align= \"justify\" dir=\"rtl\">\n",
    "<font face=\"Calibri\" size=4>\n",
    "    <h3>الگوریتم k-Nearest Neighbors (8 نمره)</h3>\n",
    "الگوریتم Naïve Bayes را از ابتدا پیاده‌سازی کنید و روی داده train، آموزش دهید. سپس با تنظیمات دلخواه (مقدار k، معیار محاسبه فاصله و ...) مدل را روی داده validation اعتبارسنجی کرده و مدل را ذخیره کنید. <br>\n",
    "توجه: مانند توجه قسمت قبل    \n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SX3C5Xwz6f5l"
   },
   "source": [
    "<div align= \"justify\" dir=\"rtl\">\n",
    "<font face=\"Calibri\" size=4>\n",
    "    <h3>الگوریتم SVM (6 نمره)</h3>\n",
    "در این بخش، با استفاده از کتابخانه sklearn و مدل SVC موجود در این کتابخانه، این مدل را روی داده train آموزش داده و سپس بر روی داده validation اعتبارسنجی نمایید و بهترین مدل را انتخاب کنید. \n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CoZyXjZs8nJe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lx6eDNvP9pLe"
   },
   "source": [
    "<div align= \"justify\" dir=\"rtl\">\n",
    "<font face=\"Calibri\" size=4>\n",
    "    <h3>ارزیابی (8نمره)</h3>\n",
    "    با استفاده از معیارهای ارزیابی زیر، عملکرد مدل را روی داده تست بررسی نمایید و مدل‌ها را با هم دیگر مقایسه کنید.\n",
    "    <ul>\n",
    "        <li>Accuracy</li>\n",
    "        <li>Precision</li>\n",
    "        <li>Recall</li>\n",
    "        <li>F1-score</li>\n",
    "        <li>Confusion Matrix</li>\n",
    "    </ul>\n",
    "    با توجه به اینکه مسئله طبقه‌بندی این پروژه از نوع چند کلاسه می‌باشد، از macro معیارهای ذکرشده، استفاده نمایید. توجه داشته باشید که می‌توانید از امکانات کتابخانه sklearn برای این قسمت استفاده نمایید.\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m7Df2x7rDpJ6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mVjG93BZJJty"
   },
   "source": [
    "<div align= \"justify\" dir=\"rtl\">\n",
    "<font face=\"Calibri\" size=4>\n",
    "    <h3>مصورسازی (10 نمره امتیازی)</h3>\n",
    "در این قسمت با استفاده از روش‌های کاهش ابعاد مانند PCA یا t-SNE داده‌های دیتاست را به یک فضایی با ابعاد پایین‌تر (2 یا 3 بعد) برده و سپس با استفاده از کتابخانه‌های مصورسازی پایتون، نمودارهای مرتبط به هر مدل را رسم نمایید. <br>\n",
    "هیچ محدودیتی برای استفاده از کتابخانه های پایتون در این بخش وجود ندارد. همچنین هر نوع نمودار مرتبط و دارای محتوای قابل قبول، برای این بخش کافی می باشد. \n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3sWI8tEqJbRA"
   },
   "source": [
    "<div align= \"justify\" dir=\"rtl\">\n",
    "<font face=\"Calibri\" size=4>\n",
    "    <h2>خوشه‌بندی (20+10 نمره)</h2>\n",
    "در این بخش می‌خواهیم دو مدل خوشه‌بندی k-means و Agglomerative Clustering را بررسی کنیم. خوشه‌بندی بر روی برچسب (label) هر خبر اجرا می‌شود. برای این قسمت، مرحله آموزش بر روی داده‌های آموزش انجام می‌شود و با استفاده از معیار purity، اعتبارسنجی روی داده‌های validation انجام می‌گردد. درنهایت نیز، مشابه قسمت طبقه‌بندی، به سنجش مدل روی داده تست می‌پردازیم. <br>\n",
    "به همین منظور کد مربوط به محاسبه معیار purity را از ابتدا در این قسمت پیاده‌سازی کنید.\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align= \"justify\" dir=\"rtl\">\n",
    "<font face=\"Calibri\" size=4>\n",
    "    توجه داشته باشید که مانند بخش طبقه‌بندی، لازم است که در انتها 6 مدل به عنوان مدل‌های نهایی برای بخش ارزیابی انتخاب شوند. این 6 مدل به صورت زیر می‌باشند:\n",
    "    <ul>\n",
    "        <li>مدل k-means آموزش داده شده روی ستون vec_1 یا embedding حاصل از عنوان خبر</li>\n",
    "        <li>مدل k-means آموزش داده شده روی ستون vec_2 یا embedding حاصل از متن خبر</li>\n",
    "        <li>مدل k-means آموزش داده شده روی ستون vec_3 یا embedding حاصل از ترکیب عنوان و متن خبر</li>\n",
    "        <li>مدل Agglomerative Clustering آموزش داده شده روی ستون vec_1 یا embedding حاصل از عنوان خبر</li>\n",
    "        <li>مدل Agglomerative Clustering آموزش داده شده روی ستون vec_2 یا embedding حاصل از متن خبر</li>\n",
    "        <li>مدل Agglomerative Clustering آموزش داده شده روی ستون vec_3 یا embedding حاصل از ترکیب عنوان و متن خبر</li>\n",
    "    </ul>\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_GwWmUdrR5Ig"
   },
   "source": [
    "<div align= \"justify\" dir=\"rtl\">\n",
    "<font face=\"Calibri\" size=4>\n",
    "    <h3>الگوریتم K-means (8 نمره)</h3>\n",
    "الگوریتم k-means را از ابتدا پیاده‌سازی کنید و سپس آن را روی داده train، آموزش داده و با داده validation اعتبارسنجی (با استفاده از معیار purity) نمایید. تعداد خوشه‌ها برابر مقدار 4 در نظر گرفته‌شود. \n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yixt8YRdOvr0"
   },
   "source": [
    "<div align= \"justify\" dir=\"rtl\">\n",
    "<font face=\"Calibri\" size=4>\n",
    "    <h3>الگوریتم Agglomerative Clustering (6 نمره)</h3>\n",
    "با استفاده از الگوریتم Agglomerative Clustering (که یک الگوریتم خوشه‌بندی از نوع hierarchical می‌باشد)  به خوشه‌بندی داده‌های دیتاست بپردازید. لازم به ذکر است که از کتابخانه sklearn برای پیاده‌سازی این قسمت می‌توانید استفاده کنید. \n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "izIe7Pc9SckR"
   },
   "source": [
    "<div align= \"justify\" dir=\"rtl\">\n",
    "<font face=\"Calibri\" size=4>\n",
    "    <h3>ارزیابی (6 نمره)</h3>\n",
    "با استفاده از معیارهای ارزیابی purity (که در ابتدای این بخش پیاده‌سازی شده بود) و معیار Adjusted Rand Index (پیاده‌سازی با استفاده از کتابخانه‌های پایتون) به سنجش عملکرد مدل‌های انتخاب شده بر روی داده تست بپردازید. \n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QktBgSKGcMda"
   },
   "source": [
    "<div align= \"justify\" dir=\"rtl\">\n",
    "<font face=\"Calibri\" size=4>\n",
    "    <h3>مصورسازی (10 نمره امتیازی)</h3>\n",
    "مشابه بخش قبل، با استفاده از روش‌های کاهش ابعاد مانند PCA یا t-SNE داده‌های دیتاست را به یک فضایی با ابعاد پایین‌تر (2 یا 3 بعد) برده و سپس با استفاده از کتابخانه‌های مصورسازی پایتون، نمودارهای مرتبط را رسم نمایید. <br>\n",
    "هیچ محدودیتی برای استفاده از کتابخانه‌های پایتون در این بخش، وجود ندارد. همچنین هر نوع نمودار مرتبط و دارای محتوای قابل قبول، برای این بخش کافی می‌باشد. \n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align= \"justify\" dir=\"rtl\">\n",
    "<font face=\"Calibri\" size=4>\n",
    "    <h1>پیاده‌سازی خزنده (crawler) و واکشی اطلاعات (40 نمره)</h1>\n",
    "    در این بخش قصد داریم تا برای سایت  ResearchGate یک خزنده پیاده‌سازی کرده و با استفاده از آن اطلاعات تعدادی مقاله را واکشی کنیم. <br>\n",
    "    اطلاعات مورد نیاز برای جمع‌آوری از هر مقاله، عبارت‌اند از:\n",
    "<ul>\n",
    "      <li>ID مقاله</li>\n",
    "      <li>عنوان مقاله</li>\n",
    "      <li>چکیده مقاله (برخی از مقالات ممکن است دارای چکیده نباشند. همچنین ممکن است در برخی از صفحات سایت، به جای عبارت Abstract، از عبارت Description برای اشاره به چکیده استفاده‌شده باشد. توصیه می‌کنیم که برخی از صفحات این سایت را بررسی کنید.)\n",
    "</li>\n",
    "      <li>سال انتشار</li>\n",
    "    <li>نام نویسندگان</li>\n",
    "    <li>لینک صفحه ارجاعات مقاله یا references (10 مورد اول - در صورت موجود نبودن، همان تعداد)</li>\n",
    "</ul>\n",
    "برای آغاز واکشی به چند لینک اولیه نیاز است. این لینک‌ها در فایل start.txt قرار دارند. در طول واکشی اطلاعات، لازم است که لینک‌های ارجاعات مقاله (reference) به همین فایل start.txt اضافه شده و برای واکشی‌های بعدی مورداستفاده قرار گیرد. توجه داشته باشید که لینک‌های ذخیره‌شده نباید تکراری باشند. <br>\n",
    "اطلاعات واکشی شده باید به‌صورت یک فایل json ذخیره شوند. یک نمونه از قالب این فایل در sample.json قرار داده‌شده است. در کل نیاز است که 2000 مقاله واکشی شوند و اطلاعات آن‌ها در یک فایل json با قالب گفته ذخیره گردد. <br><br>\n",
    "<b>نکات مهم:</b>\n",
    "    <ul>\n",
    "        <li>پیشنهاد می‌شود که از کتابخانه‌های selenium و یا scrapy زبان پایتون برای crawl کردن و از کتابخانه CSS Selector برای جستجو و دسترسی به تگ‌های HTML صفحه و محتوای آن‌ها استفاده کنید.\n",
    "</li>\n",
    "        <li>برای واکشی اطلاعات، بین هر واکشی یک مقدار delay (برای مثال 5 ثانیه) قرار دهید.</li>\n",
    "        <li>توجه داشته باشید که فرمت URL هر صفحه در سایت ResearchGate به‌صورت زیر است:\n",
    "        <div dir='ltr'>\n",
    "            https://www.researchgate.net/publication/PaperId_PaperTitle\n",
    "        </div>\n",
    "        که PaperID و PaperTitle، Id و عنوان مقاله می‌باشند.\n",
    "        </li>\n",
    "        <li>برای دسترسی به بخش ارجاعات مقاله، لازم است که عبارت references/ به انتهای URL مقاله اضافه شود و سپس واکشی انجام شود.\n",
    "</li>\n",
    "    </ul>\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align= \"justify\" dir=\"rtl\">\n",
    "<font face=\"Calibri\" size=4>\n",
    "    <h1>ارزش‌گذاری مقالات و رتبه‌بندی نویسنده‌ها (10 + 10 نمره)</h1>\n",
    "    <h2>ارزش‌گذاری مقالات با الگوریتم PageRank (10 نمره)</h2>\n",
    "    در این قسمت شما باید مقدار PageRank مقالات واکشی شده را که در فایل json کراول شده است و حاوی ۲۰۰۰ مقاله است، محاسبه کرده و یک فایل با نام PageRank.json با فرمت زیر ذخیره کنید.\n",
    "      <div dir=\"ltr\">\n",
    "            <pre class=\"line-numbers\">\n",
    "               <code class=\"language-css\">\n",
    "{\n",
    "    &ltPaperID1&gt: &ltPageRankValue1&gt,\n",
    "    &ltPaperID2&gt: &ltPageRankValue2&gt,\n",
    "    .\n",
    "    .\n",
    "    .\n",
    "}\n",
    "               </code>\n",
    "            </pre>\n",
    "      </div> \n",
    "    <b>ورودی</b>\n",
    "    <ul>\n",
    "        <li>فایل json حاوی مقالات کراول شده</li>\n",
    "        <li>مقدار alpha یا teleporting parameter</li>\n",
    "    </ul>  \n",
    "    <b>خروجی</b>\n",
    "    <ul>\n",
    "        <li>فایل PageRank.json </li>\n",
    "    </ul>\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align= \"justify\" dir=\"rtl\">\n",
    "<font face=\"Calibri\" size=4>\n",
    "    <h2>رتبه‌بندی نویسنده‌ها با الگوریتم HITS (10 نمره امتیازی)</h2>\n",
    "    حال که ارجاع میان مقالات را مورد بررسی قرار دادیم می خواهیم به رتبه‌بندی نویسندگان مقاله بر اساس HITS بپردازیم. میگوییم فرد الف به فرد ب ارجاع دارد اگر فرد الف مقاله ای نوشته باشد که به مقاله ای از فرد ب ارجاع پیدا کرده باشد. در این حالت یک یال از فرد الف به فرد ب در گراف مدل نویسندگان رسم می‌کنیم. <br>\n",
    "    حال با تعریف ذکر شده با محاسبه شاخص authority , hub نویسندگان را بر اساس authority رتبه بندی کنید. <br> \n",
    "    <b>ورودی</b>\n",
    "    <ul>\n",
    "        <li>فایل json حاوی ۲۰۰۰ مقاله </li>\n",
    "        <li>تعداد نویسندگان برتر مورد نظر(n)</li>\n",
    "    </ul>  \n",
    "    <b>خروجی</b>\n",
    "    <ul>\n",
    "        <li>لیست n نویسنده برتر  </li>\n",
    "    </ul>\n",
    "    برای پیاده سازی HITS برای تعداد دفعات اجرای حلقه می‌توانید عدد ۶ را در نظر بگیرید.\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
